{
 "metadata": {
  "name": "",
  "signature": "sha256:153423a81abe0e1e1034bd9c985d7f728307197fbaf3fe9ef7c69d05488e5424"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cluster version - successful maybe\n",
      "note that tranning set use np.linspace(0.1, 1, 100)\n",
      "comment remove - successful\n",
      "save tree to json (one tree per file) - successful\n",
      "\n",
      "modifile Dataset to use x -> (x, y, img) and more...\n",
      "but now we need to edit to create one  tree per time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file client.py\n",
      "import numpy as np\n",
      "\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Dataset\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "class Dataset:\n",
      "    '''\n",
      "    Provide dataset to out random forest\n",
      "        Spiral dataset\n",
      "    '''\n",
      "    def __init__(self, clmax, Q_length):\n",
      "        '''\n",
      "        Initial routine\n",
      "            clmax:int - maximum number of class\n",
      "            Q_length:int - size of data per class\n",
      "        '''\n",
      "        self.Q_length = Q_length    # q size per class per client\n",
      "        self.clmax = clmax;    # class max of dataset\n",
      "        \n",
      "        self.feature = 2\n",
      "        \n",
      "        self.I =  np.zeros([self.feature, 0], dtype=np.float)  # np.ndarray row vetor, hold features\n",
      "        self.L =  np.array([], dtype=np.int)    # np.array, hold label\n",
      "\n",
      "        # create I\n",
      "        for x in range(clmax): \n",
      "            theta = np.linspace(0, 2*np.pi, self.Q_length)+np.random.randn(self.Q_length)*0.4*np.pi/clmax + 2*np.pi*x/clmax \n",
      "            r = np.linspace(0.1, 1, self.Q_length)\n",
      "            \n",
      "            self.I = np.append(self.I, [r*np.cos(theta), r*np.sin(theta)], axis=1)\n",
      "            self.L = np.append(self.L, np.ones(self.Q_length, dtype=np.int)*x, axis=1)\n",
      "    \n",
      "\n",
      "    def __str__(self):\n",
      "        '''Return:\n",
      "            string that represent this class'''\n",
      "        return 'clmax: {cm}, Q_length: {ql}'.format(cm=self.clmax, ql=self.Q_length)\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# ClientNode\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "class ClientNode:\n",
      "    '''\n",
      "    This represent ClientNode which contain only data\n",
      "    we use it for simulate stack\n",
      "    '''\n",
      "    def __init__(self, bag):\n",
      "        '''\n",
      "        Init routine\n",
      "            bag:int[] - array (list) of index that point to I in Dataset\n",
      "        '''\n",
      "        self.bag = bag\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Client\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "class Client:\n",
      "    '''\n",
      "    Class in Client (Engine) side\n",
      "    Provide base orperator for random forest's tree creation\n",
      "    It did not keep each ClientNode, If it no longer use each ClientNode it will dereferance that node \n",
      "    '''\n",
      "    def __init__(self, clmax, np2c):\n",
      "        '''\n",
      "        Init routine\n",
      "            clmax:int - number of class\n",
      "            np2c:int - Number of sample Per Class Client\n",
      "        '''\n",
      "        self.clmax = clmax\n",
      "        self.np2c = np2c    # n2pc : Number of sample Per Class Client\n",
      "        \n",
      "        # init dataset\n",
      "        self.dataset = Dataset(self.clmax, self.np2c)\n",
      "        \n",
      "        self.current_node = None\n",
      "        self.queue = [ClientNode(np.arange(0, self.clmax*self.np2c))] # np.arange(0, clmax*np2c) - use all dataset\n",
      "        \n",
      "    def reset(self):\n",
      "        '''Reset current_node and queue to start state for ready to create new tree with new parameter'''\n",
      "        # init bag (queue)\n",
      "        self.current_node = None\n",
      "        self.queue = [ClientNode(np.arange(0, self.clmax*self.np2c))] # np.arange(0, clmax*np2c) - use all dataset\n",
      "    \n",
      "    def get_init_parameter(self):\n",
      "        '''Calculate init H (entropy) of first ndoe\n",
      "        This run once on each tree creation\n",
      "        Return:\n",
      "            entropy of first node in queue\n",
      "        '''\n",
      "        return self.cal_entropy(self.queue[0].bag), len(self.queue[0].bag)\n",
      "    \n",
      "    def dequeue(self):\n",
      "        '''Dequeue and set current_node to element that came from dequeue'''\n",
      "        self.current_node = self.queue.pop(0)\n",
      "        \n",
      "    def get_theta_tau(self):\n",
      "        '''Return randomed index and theta (np.array) from current_node\n",
      "        Return:\n",
      "            None, None - if current_node.bag are empty or len(theta) == 0\n",
      "            theta:np.array, tau:np.array - if current_node does not empty and len(theta) != 0\n",
      "        '''\n",
      "        if len(self.current_node.bag) != 0:        \n",
      "            #attempt = len(self.current_node.bag)//2\n",
      "            attempt = np.ceil(np.sqrt(len(self.current_node.bag)))\n",
      "\n",
      "            index = np.random.permutation(self.current_node.bag)[:attempt]\n",
      "\n",
      "            theta = np.random.randint(self.dataset.feature, size=attempt)\n",
      "            tau = self.dataset.I[theta,index]\n",
      "            \n",
      "            if len(theta) == 0:\n",
      "                return None, None\n",
      "            return theta, tau\n",
      "        return None, None\n",
      "    \n",
      "    def cal_sub_h(self, theta_list, tau_list):\n",
      "        '''Calculate sub H (entropy) of current_node (this algorithm maybe wrong) with the list of theta, tau\n",
      "        Return:\n",
      "            results:np.array - result when we try to split with each theta, tau\n",
      "            current_node bag size\n",
      "        '''\n",
      "        \n",
      "        # results = np.array\n",
      "        # for loop in list\n",
      "        #     split with theta, tau\n",
      "        #     cntAppear, P, H\n",
      "        #     add to results\n",
      "        # return results, q_length\n",
      "        \n",
      "        results = np.zeros(0, dtype=np.float)\n",
      "        for i in range(len(theta_list)):\n",
      "            theta = theta_list[i]\n",
      "            tau = tau_list[i]\n",
      "            \n",
      "            # split with theta, tau\n",
      "            l = []\n",
      "            r = []\n",
      "            for i in self.current_node.bag[:]:\n",
      "                t = self.dataset.I[theta, i]\n",
      "                if t < tau:\n",
      "                    l.append(i)\n",
      "                else:\n",
      "                    r.append(i)\n",
      "            \n",
      "            left_H = self.cal_entropy(l)\n",
      "            right_H = self.cal_entropy(r)\n",
      "            \n",
      "            results = np.append(results, [left_H*len(l) + right_H*len(r)], axis=1)\n",
      "            \n",
      "        return results, len(self.current_node.bag)\n",
      "    \n",
      "    def split(self, theta, tau):\n",
      "        '''Split current_node to left and right and add that node to queue to be process next time\n",
      "        Return:\n",
      "            h_l:float - entropy of left node\n",
      "            l:np.array - list of index in left node\n",
      "            h_r:float - entropy of right node\n",
      "            r:np.array - list of index in right node\n",
      "        '''\n",
      "        # split with theta, tau\n",
      "        l = []\n",
      "        r = []\n",
      "        for i in self.current_node.bag:\n",
      "            t = self.dataset.I[theta, i]\n",
      "            if t < tau:\n",
      "                l.append(i)\n",
      "            else:\n",
      "                r.append(i)\n",
      "        \n",
      "        left, right, h_l, l, h_r, r = ClientNode(l), ClientNode(r), self.cal_entropy(l), len(l), self.cal_entropy(r), len(r)\n",
      "        \n",
      "        # split node\n",
      "        #left, right, h_l, l, h_r, r = self.current_node.split(theta, tau)\n",
      "        \n",
      "#         print('\\tleft bag:', left.bag)\n",
      "#         print('\\tright bag:', right.bag)\n",
      "        \n",
      "        # manage queue\n",
      "        self.queue.append(left)\n",
      "        self.queue.append(right)\n",
      "        \n",
      "        # return parameter\n",
      "        return h_l, l, h_r, r\n",
      "    \n",
      "    def cal_entropy(self, lst):\n",
      "        '''Calculate entropy on lst:list(np.array)\n",
      "        Return:\n",
      "            entropy of lst\n",
      "        '''\n",
      "        # cnt appear\n",
      "        if len(lst) != 0:\n",
      "            appear = np.bincount(self.dataset.L[np.array(lst)], minlength=self.dataset.clmax)\n",
      "            appear = np.array(appear, dtype=np.float)\n",
      "        else:\n",
      "            appear = np.zeros(self.dataset.clmax)\n",
      "\n",
      "        # cal Prop\n",
      "        appear += np.finfo(np.float32).tiny\n",
      "        prop = appear/(appear.sum()*1.0)\n",
      "\n",
      "        # cal H\n",
      "        return -1*np.inner(prop, np.log2(prop))\n",
      "    \n",
      "    def cnt_appear(self):\n",
      "        '''Count appear of each class in current_node.bag\n",
      "        Return:\n",
      "            appear of each class\n",
      "        '''\n",
      "        lst = self.current_node.bag\n",
      "        # cnt appear\n",
      "        if len(lst) != 0:\n",
      "            appear = np.bincount(self.dataset.L[np.array(lst)], minlength=self.dataset.clmax)\n",
      "            appear = np.array(appear, dtype=np.float)\n",
      "        else:\n",
      "            appear = np.zeros(self.dataset.clmax)\n",
      "            \n",
      "        return appear\n",
      "    \n",
      "    def get_bag_size(self):\n",
      "        '''Return:\n",
      "            current_node bag size\n",
      "        '''\n",
      "        return np.sum(self.cnt_appear())\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    client = Client(clmax, np2c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing client.py\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file master.py\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Master\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import json\n",
      "\n",
      "import numpy as np\n",
      "from IPython import parallel\n",
      "\n",
      "class Master:\n",
      "    '''This class are on Master side in cluster'''\n",
      "    def __init__(self, clmax=5, np2c=30, max_depth=30, min_bag_size=2):\n",
      "        '''Init routine\n",
      "        That setup client\n",
      "        '''\n",
      "        self.clmax = clmax\n",
      "        self.np2c = np2c\n",
      "        self.max_depth = max_depth\n",
      "        self.min_bag_size = min_bag_size\n",
      "            \n",
      "        # init cluster client\n",
      "        self.clients = parallel.Client(packer='pickle')\n",
      "        self.clients.block = True\n",
      "\n",
      "        self.dview = self.clients.direct_view(self.clients.ids[1:])\n",
      "        self.dview.block = True\n",
      "    \n",
      "    def init_client(self):\n",
      "        # init client\n",
      "        self.dview.push({'np2c':self.np2c, 'clmax':self.clmax});\n",
      "        self.dview.run('client.py')\n",
      "    \n",
      "    def cal_init_h(self):\n",
      "        '''Calculate init entropy of each client and weighted sum it\n",
      "        Return:\n",
      "            h (entropy) of init node (use in master)\n",
      "        '''\n",
      "        hq = 0\n",
      "        sum_q = 0\n",
      "        \n",
      "        self.dview.execute('init_parameter = client.get_init_parameter()')\n",
      "        init_parameter = self.dview['init_parameter']\n",
      "        \n",
      "        for h, q in init_parameter:\n",
      "#             h, q = c.get_init_parameter()\n",
      "            hq += h*q\n",
      "            sum_q += q\n",
      "        h = hq/float(sum_q)\n",
      "        return h\n",
      "    \n",
      "    def create_tree(self):\n",
      "        '''This will create one tree per call so if u need to create more than one tree please call this multiple time\n",
      "        This method does not handle save tree process so you need to handle it in youn own way\n",
      "        This will return a root of tree that it created\n",
      "        '''\n",
      "        \n",
      "        # prepare for creation\n",
      "        H = self.cal_init_h()\n",
      "        root = MasterNode(H, 0)\n",
      "        queue = [root]\n",
      "        \n",
      "        while len(queue) != 0:\n",
      "            current_node = queue.pop(0)\n",
      "            self.dview.execute('client.dequeue()')\n",
      "\n",
      "            left, right = self.split(current_node)\n",
      "\n",
      "            if left != None:\n",
      "                current_node.left = left\n",
      "                queue.append(left)\n",
      "\n",
      "                current_node.right = right\n",
      "                queue.append(right)\n",
      "        \n",
      "        # reseting and cleanning memory\n",
      "        self.dview.execute('client.reset()')\n",
      "        #self.clients.purge_everything()\n",
      "        self.clients.purge_results('all')\n",
      "        \n",
      "        return root\n",
      "                \n",
      "    def split(self, node):\n",
      "        '''This perform 'try split' on node, then find best G finally 'real split' it\n",
      "        Return:\n",
      "            left:MasterNode\n",
      "            right:MasterNode\n",
      "        '''\n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        # check terminate case\n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        if node.depth > self.max_depth:\n",
      "#             print(list(range(node.depth + 1)), 'terminated with max_depth')\n",
      "            self.on_terminate(node)\n",
      "            return (None, None)\n",
      "        \n",
      "        # gather length of bag with scope of bag(left, right)\n",
      "        self.dview.execute('bag_size = client.get_bag_size()')\n",
      "        bag_size = self.dview['bag_size']\n",
      "        \n",
      "        #if node.depth == 0 :\n",
      "        #    print(list(range(node.depth + 1)), '\\tbag size:', sum(bag_size), bag_size)\n",
      "        \n",
      "        if not any([b > self.min_bag_size for b in bag_size]): # sum across client\n",
      "#             print(list(range(node.depth + 1)), 'terminated with min_bag_size')\n",
      "            self.on_terminate(node)\n",
      "            return (None, None)\n",
      "        \n",
      "        g = self.cal_information_gain(node)\n",
      "        if g <= 0:\n",
      "#             print(list(range(node.depth + 1)), 'terminated with G')\n",
      "            self.on_terminate(node)\n",
      "            return (None, None)\n",
      "        \n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        # client: split with theta, tau\n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        #print('trying split')\n",
      "        self.dview.push({'theta':node.theta, 'tau':node.tau})\n",
      "        self.dview.execute('split_result = client.split(theta, tau)')\n",
      "        split_result = self.dview['split_result']\n",
      "        \n",
      "        h_left = 0\n",
      "        h_right = 0\n",
      "        q_left = 0\n",
      "        q_right = 0\n",
      "        for h_l, q_l, h_r, q_r in split_result:\n",
      "            h_left += h_l*q_l\n",
      "            h_right += h_r*q_r\n",
      "            \n",
      "            q_left += q_l\n",
      "            q_right += q_r\n",
      "        h_left = h_left/float(q_left)\n",
      "        h_right = h_right/float(q_right)\n",
      "        \n",
      "        return MasterNode(h_left, node.depth+1), MasterNode(h_right, node.depth+1)\n",
      "    \n",
      "    def cal_information_gain(self, node):\n",
      "        '''Calculate information gain on node\n",
      "        Return:\n",
      "            G:float\n",
      "        '''\n",
      "        # collect theta_tau\n",
      "        self.dview.execute('theta_taus = client.get_theta_tau()')\n",
      "        \n",
      "        theta_taus = self.dview['theta_taus']\n",
      "        \n",
      "        theta_list = np.array([], dtype=np.int)\n",
      "        tau_list = np.array([])\n",
      "        for theta, tau in theta_taus:\n",
      "            if theta == None and tau == None:\n",
      "                continue\n",
      "            theta_list = np.append(theta_list, theta, axis=1)\n",
      "            tau_list = np.append(tau_list, tau, axis=1)\n",
      "        \n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        # distribute & gather\n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        self.dview.push({'theta_list': theta_list, 'tau_list':tau_list})\n",
      "        self.dview.execute('sub_h = client.cal_sub_h(theta_list, tau_list)')\n",
      "        sub_h = self.dview['sub_h']\n",
      "        sub_hs = np.empty([len(self.dview), len(theta_list)], dtype=np.float)\n",
      "        size = []\n",
      "        for i, (result, q_size) in enumerate(sub_h):\n",
      "            sub_hs[i,:] = result\n",
      "            size.append(q_size)\n",
      "#         print(size)\n",
      "    \n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        # cal g\n",
      "        # -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "        # sum over client\n",
      "        h_of_iteration = np.sum(sub_hs, axis=0)\n",
      "        \n",
      "        # cal new (and complete) H\n",
      "        new_h = h_of_iteration/float(sum(size))\n",
      "        \n",
      "#         print(list(range(node.depth + 1)), 'new_h: ', new_h)\n",
      "        \n",
      "        # cal g\n",
      "        g = node.old_h - new_h\n",
      "        \n",
      "#         print(list(range(node.depth + 1)), 'g: ', g)\n",
      "        \n",
      "        # find best g\n",
      "        best_g_idx = np.argmax(g)\n",
      "        \n",
      "        # svae parameter\n",
      "        node.theta = theta_list[best_g_idx]\n",
      "        node.tau = tau_list[best_g_idx]\n",
      "        \n",
      "#         print(list(range(node.depth + 1)), 'parameter saved on:', str(node))\n",
      "        \n",
      "        return g[best_g_idx]\n",
      "    \n",
      "    def on_terminate(self, node):\n",
      "        '''This are call when we reach termonate case (3 cases)\n",
      "        It will save prop of each class onto node:MasterNode'''\n",
      "        \n",
      "        self.dview.execute('appear = client.cnt_appear()')\n",
      "        appear = self.dview['appear']\n",
      "        \n",
      "        appears = []\n",
      "        for a in appear:\n",
      "            appears.append(a)\n",
      "        appears = np.array(appears, dtype=np.float)\n",
      "        appears = np.sum(appears, axis=0)/np.sum(appears)\n",
      "        \n",
      "        node.prop = appears\n",
      "        \n",
      "        #print(list(range(node.depth + 1)), '\\tprop saved on:', str(node))\n",
      "    \n",
      "    def get_results(self, roots, I):\n",
      "        '''This use for get result from multiple dicision tree on master for feature list I'''\n",
      "        props = []\n",
      "        for root in roots:\n",
      "            props.append(self._get_result(root, I))\n",
      "        props = np.array(props)\n",
      "        return np.sum(props, axis=0)/len(roots)\n",
      "    \n",
      "    def get_result(self, tree, I):\n",
      "        '''This use for get result from tree:int dicision tree on master for feature list I'''\n",
      "        return self._get_result(tree, I)\n",
      "    \n",
      "    def _get_result(self, node, I):\n",
      "        '''This use for get result from dicision tree on master for feature list I (recursive)'''\n",
      "        if node.prop != None:\n",
      "            return node.prop\n",
      "        \n",
      "        tau = I[node.theta]\n",
      "\n",
      "        if node.left and tau < node.tau:\n",
      "            return self._get_result(node.left, I)\n",
      "        if node.right and tau >= node.tau:\n",
      "            return self._get_result(node.right, I)\n",
      "        return -1  # for unknow\n",
      "    \n",
      "    def _node_to_dict(self, node):\n",
      "        if node == None:\n",
      "            return None\n",
      "\n",
      "        result = {}\n",
      "\n",
      "        if node.prop == None:\n",
      "            result['prop'] = None\n",
      "        else:\n",
      "            result['prop'] = list(node.prop)\n",
      "            \n",
      "        if node.theta == None :\n",
      "            result['theta'] = None\n",
      "            result['tau'] = None\n",
      "        else:\n",
      "            result['theta'] = np.asscalar(node.theta)\n",
      "            result['tau'] = np.asscalar(node.tau)\n",
      "\n",
      "        result['left'] = self._node_to_dict(node.left)\n",
      "        result['right'] = self._node_to_dict(node.right)\n",
      "\n",
      "        return result\n",
      "    \n",
      "    def _dict_to_node(self, dict_):\n",
      "        if dict_ == None:\n",
      "            return None\n",
      "        \n",
      "        root = MasterNode()\n",
      "        \n",
      "        if dict_['prop'] == None:\n",
      "            root.prop = None\n",
      "        else:\n",
      "            root.prop = np.array(dict_['prop'])\n",
      "            \n",
      "        if dict_['theta'] == None:\n",
      "            root.theta = None\n",
      "            root.tau = None\n",
      "        else:\n",
      "            root.theta = np.int32(dict_['theta'])\n",
      "            root.tau = np.float64(dict_['tau'])\n",
      "            \n",
      "        root.left = self._dict_to_node(dict_['left'])\n",
      "        root.right = self._dict_to_node(dict_['right'])\n",
      "        \n",
      "        return root\n",
      "    \n",
      "    def save_tree(self, tree, filename=None):\n",
      "        '''\n",
      "        Write selected decision tree to files,\n",
      "        '''\n",
      "        if filename == None:\n",
      "            filename = 'tree_{}.json'.format(time.strftime(\"%c\"))\n",
      "        \n",
      "        f = open(filename, 'w')\n",
      "        result = self._node_to_dict(tree)\n",
      "        json.dump(result, f, indent=2)\n",
      "        f.close()\n",
      "    \n",
      "    def load_tree(self, filename):\n",
      "        '''\n",
      "        Read decision tree from file\n",
      "        '''\n",
      "        f = open(filename, 'r')\n",
      "        dict_ = json.load(f)\n",
      "        f.close()\n",
      "        root = self._dict_to_node(dict_)\n",
      "        return root\n",
      "        \n",
      "    def load_trees(self, path='.', prefix='tree'):\n",
      "        '''\n",
      "        Read set of decision tree from set of files that match prefix\n",
      "        '''\n",
      "        # fectch file list in target folder\n",
      "        treefiles = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.startswith(prefix)]\n",
      "        roots = []\n",
      "        for f in treefiles:\n",
      "            roots.append(self.load_tree(os.path.join(path, f)))\n",
      "        \n",
      "        return roots\n",
      "    \n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# MasterNode\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "class MasterNode:\n",
      "    def __init__(self, old_h=None, depth=None):\n",
      "        self.theta = None\n",
      "        self.tau = None\n",
      "        \n",
      "        self.prop = None\n",
      "        \n",
      "        self.old_h = old_h\n",
      "        self.depth = depth\n",
      "        \n",
      "        self.left = None\n",
      "        self.right = None\n",
      "    \n",
      "    def __str__(self):\n",
      "        return 'm_node@{d} theta: {tt}, tau: {t}, prop: {p}'.format(d=self.depth, tt=self.theta, t=self.tau, p=self.prop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing master.py\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file main.py\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Main\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "import sys\n",
      "import time\n",
      "\n",
      "from master import Master\n",
      "import test\n",
      "\n",
      "def main(clmax, np2c, tree_file_format):\n",
      "    number_of_tree = 3\n",
      "    \n",
      "    master = Master(clmax=clmax, np2c=np2c, max_depth=30, min_bag_size=2)\n",
      "    master.init_client()\n",
      "\n",
      "    #stdout_file = 'tree_{}_{}_devie_by_2_evaluation'.format(master.clmax, master.np2c)\n",
      "    #sys.stdout = open(stdout_file, 'w')\n",
      "\n",
      "    print('~{ Random Forest Parameter }~')\n",
      "    print('clmax:', master.clmax)\n",
      "    print('np2c:', master.np2c)\n",
      "    print('max depth:', master.max_depth)\n",
      "    print('min bag size:', master.min_bag_size)\n",
      "    \n",
      "    print('Will create {} tree(s):'.format(number_of_tree))\n",
      "    \n",
      "    total_run_time = 0\n",
      "    # loop to create trees\n",
      "    for i in range(number_of_tree):\n",
      "        print('\\nCreating tree {}...'.format(i))\n",
      "        \n",
      "        start_time = time.time()\n",
      "        t = master.create_tree()\n",
      "        end_time = time.time()\n",
      "        \n",
      "        run_time = end_time - start_time\n",
      "        total_run_time += run_time\n",
      "        print('Run time: {} sec'.format(run_time))\n",
      "        print('Saving...')\n",
      "        master.save_tree(t, tree_file_format.format(clmax=master.clmax, np2c=master.np2c, index=i))\n",
      "\n",
      "    print('\\n{} Tree(s) creation successful'.format(number_of_tree))\n",
      "    print('Total run time: {} sec'.format(total_run_time))\n",
      "    print('Avg run time per tree: {} sec'.format(1.0*total_run_time/number_of_tree*1.0))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    if len(sys.argv) < 3:\n",
      "        print('Usage: ', sys.argv[0], ' <clmax> <np2c> <tree_file_format or default:tree_{clmax}_{np2c}_sqrt_2_evaluation_{index}.json>')\n",
      "        sys.exit(1)\n",
      "    \n",
      "    clmax = int(sys.argv[1])\n",
      "    np2c = int(sys.argv[2])\n",
      "    tree_file_format = 'tree_{clmax}_{np2c}_sqrt_2_evaluation_{index}.json'\n",
      "    \n",
      "    if len(sys.argv) == 3:\n",
      "        main(clmax, np2c, tree_file_format)\n",
      "    elif len(sys.argv) == 4:\n",
      "        tree_file_format = sys.argv[3]\n",
      "        main(clmax, np2c, tree_file_format)\n",
      "        \n",
      "    test.main(int(sys.argv[1]), tree_file_format[:-13].format(clmax=clmax, np2c=np2c))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing main.py\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file test.py\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: % Correct on one multiple trees\n",
      "# It load tree before testing\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "import sys\n",
      "import random\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from master import Master\n",
      "\n",
      "class Record:\n",
      "    def __init__(self, features, label):\n",
      "        self.features = features\n",
      "        self.label = label\n",
      "\n",
      "def dataSetGenerator(clmax):\n",
      "    data = []\n",
      "    for x in range(clmax):\n",
      "        theta = np.linspace(0, 2*np.pi, 100)+np.random.randn(100)*0.4*np.pi/clmax + 2*np.pi*x/clmax\n",
      "        r = np.linspace(0.1, 1, 100)\n",
      "        xPoints = r*np.cos(theta)\n",
      "        yPoints = r*np.sin(theta)\n",
      "        for i in range(len(xPoints)):\n",
      "            data.append(Record([xPoints[i], yPoints[i]], x))\n",
      "    return data\n",
      "\n",
      "def main(clmax, prefix):\n",
      "    # generate dataset for test\n",
      "    dataset = dataSetGenerator(clmax)\n",
      "\n",
      "    master = Master() \n",
      "    roots = master.load_trees(prefix=prefix)\n",
      "\n",
      "    sampling_rate = 30\n",
      "    samples = int(sampling_rate*len(dataset)/100)\n",
      "\n",
      "    corrects = []\n",
      "    for x in range(100) :\n",
      "        correct = 0\n",
      "        for i in random.sample(range(len(dataset)), samples):\n",
      "            expt = dataset[i].label\n",
      "            res = np.argmax(master.get_results(roots, dataset[i].features))\n",
      "            if res == expt:\n",
      "                correct += 1\n",
      "        corrects.append(correct)\n",
      "\n",
      "    #print('Correct: ', corrects)\n",
      "    corrects = sum(corrects)/len(corrects)\n",
      "    print('\\nTesting with clmax: {}'.format(clmax))\n",
      "    print('Correct/Total: {c}/{t}'.format(c=corrects, t=samples))\n",
      "    print('% Correct from {} tree(s): {}%'.format(3, float(corrects)/float(samples)*100))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    if len(sys.argv) < 3:\n",
      "        print('Usage: ', sys.argv[0], ' <clmax> <tree_prefix>')\n",
      "        sys.exit(1)\n",
      "    main(int(sys.argv[1]), sys.argv[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting test.py\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Flat map\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from master import Master\n",
      "\n",
      "master = Master() \n",
      "roots = master.load_trees(prefix='tree_5_100_devie_by_2_evaluation')\n",
      "\n",
      "plt.hold(True)\n",
      "plt.figure(1)\n",
      "for t in range(3):\n",
      "    plt.subplot(2, 2, t+1)\n",
      "    x, y = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
      "    z = np.array([], dtype=np.float)\n",
      "    for i in range(100):\n",
      "        cls = []\n",
      "        for j in range(100):\n",
      "            cls.append(np.argmax(master.get_result(roots[t], (x[i][j], y[i][j]))))\n",
      "        z = np.append(z, cls)\n",
      "    z = z.reshape(100, 100)\n",
      "    plt.pcolormesh(x, y, z)\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Inter map\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "plt.hold(True)\n",
      "plt.figure(1)\n",
      "plt.subplot(2, 2, 4)\n",
      "\n",
      "x, y = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
      "z = np.array([], dtype=np.float)\n",
      "for i in range(100):\n",
      "    cls = []\n",
      "    for j in range(100):\n",
      "        cls.append(np.argmax(master.get_results(roots, (x[i][j], y[i][j]))))\n",
      "    z = np.append(z, cls)\n",
      "z = z.reshape(100, 100)\n",
      "plt.pcolormesh(x, y, z)\n",
      "\n",
      "plt.axis([-1, 1, -1, 1])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRpdv8PQL8SMzyh5WQAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f3587d24080>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Sub plot\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.gridspec import GridSpec\n",
      "from time import time\n",
      "from math import log, ceil\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import random\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Set Path\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "path = os.path.join('test_result')\n",
      "i = ceil(len(os.listdir(path))/2)\n",
      "sys.stdout = open(os.path.join(path, 'figure_%s.txt'%i), 'w')\n",
      "fig_path = os.path.join(path, 'figure_%s.png'%i)\n",
      "\n",
      "\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Dataset\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "markers=('r','g','b','c','m','y','k', 'w')\n",
      "m_type = ['o', '^', 'x']\n",
      "\n",
      "class Record:\n",
      "    def __init__(self, features, label):\n",
      "        self.features = features\n",
      "        self.label = label\n",
      "\n",
      "clmax = 7\n",
      "def dataSetGenerator(markers=('rx','gx','bx','cx','mx','yx','kx')):\n",
      "    data = []\n",
      "    for x in range(clmax):\n",
      "        theta = np.linspace(0, 2*np.pi, 100)+np.random.randn(100)*0.4*np.pi/clmax + 2*np.pi*x/clmax\n",
      "        r = np.linspace(0.1, 1, 100)\n",
      "        xPoints = r*np.cos(theta)\n",
      "        yPoints = r*np.sin(theta)\n",
      "        for i in range(len(xPoints)):\n",
      "            data.append(Record([xPoints[i], yPoints[i]], x))\n",
      "    return data\n",
      "dataset = dataSetGenerator(markers)\n",
      "sampling_rate = 15\n",
      "samples = int(sampling_rate*len(dataset)/100)\n",
      "\n",
      "\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Testttt\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "attemp_test = 1\n",
      "number_of_intervels = 2 #6\n",
      "\n",
      "accuracy = [[] for i in range(attemp_test)]\n",
      "log_sample = [[] for i in range(attemp_test)]\n",
      "run_times = [[0 for j in range(number_of_intervels)] for i in range(attemp_test)]\n",
      "\n",
      "for test in range(attemp_test) :\n",
      "    sample = 15\n",
      "    for interval in range(number_of_intervels) :\n",
      "        sample *= 2\n",
      "        # create tree\n",
      "        master = Master(clmax, sample)\n",
      "        start = time()\n",
      "        master.create_tree()\n",
      "        end = time()\n",
      "        run_times[test][interval] +=  end-start\n",
      "        \n",
      "        # create test data\n",
      "        dataset = dataSetGenerator()\n",
      "        \n",
      "        # testing\n",
      "        sampling_rate = 30\n",
      "        samples = int(sampling_rate*len(dataset)/100)\n",
      "\n",
      "        corrects = []\n",
      "        for x in range(100) :\n",
      "            correct = 0\n",
      "            for i in random.sample(range(len(dataset)), samples):\n",
      "                expt = dataset[i].label\n",
      "                res = np.argmax(master.get_results(dataset[i].features))\n",
      "                if res == expt:\n",
      "                    correct += 1\n",
      "            corrects.append(correct)\n",
      "\n",
      "        corrects = sum(corrects)/len(corrects)\n",
      "        accuracy[test].append(float(corrects)/float(samples)*100)\n",
      "        log_sample[test].append(log((sample*5)*2, 10))\n",
      "    run_times[test] = [run_time/master.number_of_tree for run_time in run_times[test]]\n",
      "print('Accuracy: ', accuracy)\n",
      "print('log of sample: ', log_sample)\n",
      "print('avg runtime: ', run_times)\n",
      "\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: plot\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\n",
      "\n",
      "plt.figure(figsize=(25, 15))\n",
      "gs_size = (3,6)\n",
      "flat_map_gs = [plt.subplot2grid(gs_size, (0, 0)), plt.subplot2grid(gs_size, (1, 0)), plt.subplot2grid(gs_size, (2, 0))] \n",
      "inter_map_gs = plt.subplot2grid(gs_size, (0, 1), rowspan=3, colspan=4)\n",
      "stat_gs = plt.subplot2grid(gs_size, (0,5), rowspan=2, colspan=2)\n",
      "# stat_gs.set_title('Sample')\n",
      "time_gs = plt.subplot2grid(gs_size, (2,5), colspan=2)\n",
      "# time_gs.set_title('Run Time')\n",
      "plt.tight_layout(pad=3.5)\n",
      "\n",
      "\n",
      "\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Flat map\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "for t in range(master.number_of_tree):\n",
      "    x, y = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
      "    z = np.array([], dtype=np.float)\n",
      "    for i in range(100):\n",
      "        cls = []\n",
      "        for j in range(100):\n",
      "            cls.append(np.argmax(master.get_result(t, (x[i][j], y[i][j]))))\n",
      "        z = np.append(z, cls)\n",
      "    z = z.reshape(100, 100)\n",
      "    flat_map_gs[t].pcolormesh(x, y, z)\n",
      "    flat_map_gs[t].axis([-1, 1, -1, 1])\n",
      "        \n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: inter map plot\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "x, y = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
      "z = np.array([], dtype=np.float)\n",
      "for i in range(100):\n",
      "    cls = []\n",
      "    for j in range(100):\n",
      "        cls.append(np.argmax(master.get_results((x[i][j], y[i][j]))))\n",
      "    z = np.append(z, cls)\n",
      "z = z.reshape(100, 100)\n",
      "inter_map_gs.pcolormesh(x, y, z)\n",
      "# loop to plot dataset\n",
      "c_counter = 0\n",
      "\n",
      "# for c in master.dview:\n",
      "#     for i in range(c.dataset.I.shape[1]):\n",
      "#         inter_map_gs.plot(c.dataset.I[0,i], c.dataset.I[1,i], markers[c.dataset.L[i]+1][:1]+m_type[c_counter])\n",
      "#     c_counter += 1\n",
      "\n",
      "# c = master.dview[-1]\n",
      "# for i in range(c.dataset.I.shape[1]):\n",
      "#         inter_map_gs.plot(c.dataset.I[0,i], c.dataset.I[1,i], markers[c.dataset.L[i]]+m_type[c_counter])\n",
      "# inter_map_gs.axis([-1, 1, -1, 1])\n",
      "\n",
      "for record in dataset :\n",
      "    inter_map_gs.plot(record.features[0], record.features[1], markers[record.label]+m_type[c_counter])\n",
      "inter_map_gs.axis([-1, 1, -1, 1])\n",
      "\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: plot stat\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "for test in range(attemp_test) :\n",
      "    stat_gs.plot(log_sample[test], accuracy[test])\n",
      "    stat_gs.set_ylabel('Accuracy', fontsize=18)\n",
      "    time_gs.plot(log_sample[test], run_times[test])\n",
      "    time_gs.set_ylabel('Runtime', fontsize=18)\n",
      "    \n",
      "\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "# Testing: Disply\n",
      "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "plt.savefig(fig_path)\n",
      "sys.stdout.close()\n",
      "plt.show()\n",
      "pritn(\"Test successful\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir test_result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}